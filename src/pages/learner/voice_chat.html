<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Voice Chat Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 600px;
            width: 100%;
            padding: 40px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 28px;
        }

        .config-section {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .input-group {
            margin-bottom: 15px;
        }

        label {
            display: block;
            font-weight: 600;
            color: #555;
            margin-bottom: 5px;
            font-size: 14px;
        }

        input[type="text"], select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            transition: border-color 0.3s;
        }
        
        input[type="text"] {
            font-family: 'Courier New', monospace;
        }
        
        select {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            cursor: pointer;
            background-color: white;
        }

        input[type="text"]:focus, select:focus {
            outline: none;
            border-color: #667eea;
        }
        
        input[type="text"]:read-only {
            background-color: #f8f9fa;
            cursor: not-allowed;
        }

        .hint {
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }

        .control-section {
            text-align: center;
            margin: 30px 0;
        }

        .btn {
            padding: 15px 40px;
            font-size: 16px;
            font-weight: 600;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s;
            margin: 5px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        .btn-connect {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-connect:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        .btn-connect:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .btn-disconnect {
            background: #dc3545;
            color: white;
        }

        .btn-disconnect:hover {
            background: #c82333;
            transform: translateY(-2px);
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            font-size: 48px;
            border: none;
            cursor: pointer;
            transition: all 0.3s;
            margin: 20px auto;
            display: block;
            box-shadow: 0 8px 25px rgba(245, 87, 108, 0.4);
        }

        .mic-button:hover {
            transform: scale(1.05);
        }

        .mic-button:active, .mic-button.recording {
            background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
            transform: scale(0.95);
            box-shadow: 0 4px 15px rgba(250, 112, 154, 0.6);
        }

        .mic-button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .image-display {
            text-align: center;
            margin: 20px 0;
        }

        .image-container {
            display: inline-block;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
            background: #f8f9fa;
            border: 3px solid #e0e0e0;
            max-width: 400px;
            margin: 0 auto;
        }

        .display-image {
            width: 100%;
            height: auto;
            display: block;
            max-height: 300px;
            object-fit: contain;
        }

        .image-placeholder {
            padding: 40px;
            color: #888;
            font-size: 16px;
            background: linear-gradient(45deg, #f8f9fa 25%, transparent 25%), 
                        linear-gradient(-45deg, #f8f9fa 25%, transparent 25%), 
                        linear-gradient(45deg, transparent 75%, #f8f9fa 75%), 
                        linear-gradient(-45deg, transparent 75%, #f8f9fa 75%);
            background-size: 20px 20px;
            background-position: 0 0, 0 10px, 10px -10px, -10px 0px;
        }

        .image-info {
            padding: 10px;
            background: #667eea;
            color: white;
            font-size: 12px;
            font-weight: 600;
        }

        .mood-info {
            display: inline-block;
            margin-right: 10px;
        }

        .servo-info {
            display: inline-block;
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            font-weight: 600;
        }

        .status.disconnected {
            background: #f8d7da;
            color: #721c24;
        }

        .status.connecting {
            background: #fff3cd;
            color: #856404;
            animation: pulse 1.5s infinite;
        }

        .status.connected {
            background: #d4edda;
            color: #155724;
        }

        .status.listening {
            background: #fff3cd;
            color: #856404;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .log-section {
            margin-top: 30px;
        }

        .log-title {
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .log-box {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 15px;
            border-radius: 10px;
            height: 200px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 13px;
            line-height: 1.6;
        }

        .log-box::-webkit-scrollbar {
            width: 8px;
        }

        .log-box::-webkit-scrollbar-track {
            background: #2d2d2d;
        }

        .log-box::-webkit-scrollbar-thumb {
            background: #555;
            border-radius: 4px;
        }

        .log-entry {
            margin-bottom: 5px;
        }

        .log-time {
            color: #858585;
        }

        .log-success {
            color: #4ec9b0;
        }

        .log-error {
            color: #f48771;
        }

        .log-info {
            color: #9cdcfe;
        }

        .transcript-box {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 15px;
            margin-top: 20px;
            min-height: 80px;
        }

        .transcript-label {
            font-weight: 600;
            color: #555;
            margin-bottom: 10px;
            font-size: 14px;
        }

        .transcript-text {
            color: #333;
            font-size: 16px;
            line-height: 1.6;
        }

        .help-text {
            text-align: center;
            color: #888;
            font-size: 14px;
            margin-top: 20px;
        }

        .mode-switch {
            display: flex;
            flex-direction: column;
            gap: 10px;
            margin-top: 10px;
        }

        .mode-switch input[type="radio"] {
            display: none;
        }

        .mode-label {
            display: flex;
            align-items: center;
            padding: 12px 16px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 500;
            background: white;
        }

        .mode-label:hover {
            border-color: #667eea;
            background: #f8f9fa;
        }

        .mode-switch input[type="radio"]:checked + .mode-label {
            border-color: #667eea;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .advanced-section {
            margin-top: 15px;
        }

        .expand-toggle {
            background: none;
            border: none;
            color: #667eea;
            cursor: pointer;
            font-size: 14px;
            font-weight: 600;
            padding: 8px 0;
            display: flex;
            align-items: center;
            gap: 8px;
            transition: all 0.3s;
        }

        .expand-toggle:hover {
            color: #764ba2;
        }

        .expand-toggle .arrow {
            transition: transform 0.3s;
            display: inline-block;
        }

        .expand-toggle.expanded .arrow {
            transform: rotate(90deg);
        }

        .advanced-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }

        .advanced-content.show {
            max-height: 500px;
        }

        /* Text Chat Styles */
        .chat-container {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            margin: 20px 0;
            height: 400px;
            overflow-y: auto;
            padding: 15px;
        }

        .chat-messages {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .chat-message {
            padding: 12px 16px;
            border-radius: 12px;
            max-width: 80%;
            word-wrap: break-word;
            line-height: 1.5;
            font-size: 15px;
        }

        .chat-message.user {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            align-self: flex-end;
            margin-left: auto;
        }

        .chat-message.assistant {
            background: #e9ecef;
            color: #333;
            align-self: flex-start;
        }

        .chat-message.system {
            background: #fff3cd;
            color: #856404;
            align-self: center;
            text-align: center;
            font-size: 14px;
            font-style: italic;
        }

        .chat-message.loading {
            background: #e9ecef;
            color: #666;
            align-self: flex-start;
            font-style: italic;
        }

        .chat-message.loading::after {
            content: '';
            animation: dots 1.5s infinite;
        }

        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }

        .chat-message.image {
            background: transparent;
            padding: 0;
            max-width: 90%;
        }

        .chat-image-container {
            display: flex;
            gap: 8px;
            flex-wrap: wrap;
        }

        .chat-image-container img {
            width: 75px;
            height: 75px;
            object-fit: cover;
            display: block;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .chat-message.function-call {
            background: #fff9e6;
            border-left: 3px solid #ffc107;
            max-width: 85%;
        }

        .function-call-header {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 8px;
            font-weight: 600;
            color: #f57c00;
        }

        .function-call-icon {
            font-size: 18px;
        }

        .function-call-name {
            font-family: 'Courier New', monospace;
            color: #e65100;
        }

        .function-call-args {
            background: #f5f5f5;
            border-radius: 6px;
            padding: 8px 12px;
            font-family: 'Courier New', monospace;
            font-size: 13px;
            color: #555;
            margin-top: 6px;
            white-space: pre-wrap;
            word-break: break-word;
        }

        .function-call-label {
            font-size: 11px;
            color: #888;
            margin-bottom: 4px;
            font-weight: 600;
            text-transform: uppercase;
        }

        .chat-input-container {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }

        .chat-input {
            flex: 1;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 15px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
        }

        .chat-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .chat-input:disabled {
            background-color: #f8f9fa;
            cursor: not-allowed;
        }

        .btn-send {
            padding: 12px 30px;
            font-size: 15px;
            font-weight: 600;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            transition: all 0.3s;
        }

        .btn-send:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }

        .btn-send:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: #888;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: #555;
        }

        /* Image display inside text chat */
        #textChatImageDisplay {
            margin: 15px 0;
        }

        /* Hide voice image display when in text mode */
        #textChatControls ~ #voiceImageDisplay {
            display: block;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice Chat Demo</h1>

        <div class="config-section">
            <div class="input-group">
                <label for="todoSelect">Select Todo</label>
                <select id="todoSelect">
                    <option value="">Loading todos...</option>
                </select>
                <div class="hint">Select a todo list for conversation</div>
            </div>
            
            <div class="input-group">
                <label for="todoId">Todo ID (auto-filled)</label>
                <input type="text" id="todoId" value="" readonly>
                <div class="hint">Automatically filled from selected todo</div>
            </div>
            
            <div class="advanced-section">
                <button class="expand-toggle" id="advancedToggle">
                    <span class="arrow">‚ñ∂</span>
                    <span>Advanced Settings</span>
                </button>
                <div class="advanced-content" id="advancedContent">
                    <div class="input-group">
                        <label for="userId">User ID</label>
                        <input type="text" id="userId" placeholder="Enter User ID" value="string">
                        <div class="hint">Required for conversation initialization</div>
                    </div>
                    
                    <div class="input-group">
                        <label for="asrType">ASR Type</label>
                        <select id="asrType">
                            <option value="grpc">gRPC ASR</option>
                            <option value="grpc_silero">gRPC + Silero VAD</option>
                            <option value="google_silero">Google + Silero VAD</option>
                            <option value="google">Google STT</option>
                        </select>
                        <div class="hint">Select ASR (Automatic Speech Recognition) engine</div>
                    </div>
                    
                    <div class="input-group">
                        <label for="wsUrl">WebSocket URL</label>
                        <input type="text" id="wsUrl" value="ws://localhost:8000/ws/voice-chat">
                        <div class="hint">Auto-detected from current page location</div>
                    </div>
                </div>
            </div>
            
            <div class="input-group">
                <label>Mode Selection</label>
                <div class="mode-switch">
                    <input type="radio" id="modeStt" name="audioMode" value="stt">
                    <label for="modeStt" class="mode-label">üé§ STT Mode (Web Speech API)</label>
                    
                    <input type="radio" id="modeDirectAudio" name="audioMode" value="direct" checked>
                    <label for="modeDirectAudio" class="mode-label">üéµ Direct Audio (16kHz PCM)</label>
                    
                    <input type="radio" id="modeTextChat" name="audioMode" value="text">
                    <label for="modeTextChat" class="mode-label">üí¨ Text Chat Mode</label>
                </div>
                <div class="hint">STT: Speech-to-text. Direct: Stream raw audio. Text: Text-based chat.</div>
            </div>
        </div>

        <div class="control-section">
            <button class="btn btn-connect" id="connectBtn">üîå Connect & Auto-Start</button>
            <button class="btn btn-disconnect" id="disconnectBtn" style="display: none;">‚ùå Disconnect</button>
        </div>

        <div class="status disconnected" id="status">
            ‚ùå Disconnected
        </div>

        <div style="text-align: center;" id="voiceControls">
            <button class="mic-button" id="micBtn" disabled>üé§</button>
            <div class="help-text">
                <span id="helpText">Nh·∫•n n√∫t mic ho·∫∑c Space ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m (T·ª± ƒë·ªông d·ª´ng khi server ph·∫£n h·ªìi)</span>
            </div>
        </div>

        <!-- Text Chat UI -->
        <div id="textChatControls" style="display: none;">
            <div class="chat-container" id="chatContainer">
                <div class="chat-messages" id="chatMessages">
                    <div class="chat-message system">üí¨ Start chatting by typing a message below...</div>
                </div>
            </div>
            
            <div class="chat-input-container">
                <input type="text" id="chatInput" class="chat-input" placeholder="Type your message here..." disabled>
                <button id="sendBtn" class="btn-send" disabled>Send</button>
            </div>
        </div>

        <!-- Image Display Section (for voice modes) -->
        <div class="image-display" id="voiceImageDisplay">
            <div class="image-container" id="voiceImageContainer" style="display: none;">
                <img class="display-image" id="voiceDisplayImage" alt="Server Response Image">
                <div class="image-info" id="voiceImageInfo">
                    <span class="mood-info" id="voiceMoodInfo"></span>
                    <span class="servo-info" id="voiceServoInfo"></span>
                </div>
            </div>
            <div class="image-placeholder" id="voiceImagePlaceholder">
                üñºÔ∏è Ch·ªù h√¨nh ·∫£nh t·ª´ server...
            </div>
        </div>

        <div class="transcript-box">
            <div class="transcript-label">üìù Transcript:</div>
            <div class="transcript-text" id="transcript">Ch∆∞a c√≥ vƒÉn b·∫£n...</div>
        </div>

        <div class="log-section">
            <div class="log-title">
                üìã Log
                <button onclick="clearLogs()" style="margin-left: auto; padding: 5px 10px; border: none; border-radius: 5px; background: #667eea; color: white; cursor: pointer; font-size: 12px;">Clear Logs</button>
            </div>
            <div class="log-box" id="logBox"></div>
        </div>
    </div>

    <script>
    let ws = null;
    let recognition = null;
        let audioContext = null;
        let isRecording = false;
        let currentSourceNode = null;
        let isPlayingAudio = false;
        let audioQueue = [];
        let nextPlayTime = 0;
    let recognitionWatchdog = null;
    let lastRecognitionEventAt = 0;
    const RECOG_WATCHDOG_MS = 15000; // restart recognition if no events for 15s while recording
    let isMuted = false; // Mute incoming audio while user is speaking (Space pressed)
        let masterGain = null; // Master volume controller for instant mute
        const activeSources = new Set(); // Track all scheduled/playing sources
        let dropUntilTs = 0; // Ignore incoming audio until this wall-clock time (ms)
        let audioMode = 'direct'; // 'stt' or 'direct'
        let mediaRecorder = null;
        let audioStream = null;
        let audioWorkletNode = null; // AudioWorklet node for PCM recording
        let recordingAudioContext = null; // Separate context for recording
        
        // Log level system
        const LOG_LEVEL = {
            DEBUG: 0,
            INFO: 1,
            WARN: 2,
            ERROR: 3,
            NONE: 999
        };
        let currentLogLevel = LOG_LEVEL.INFO; // Default to INFO, can be changed to DEBUG for verbose
        let logBuffer = []; // Buffer for batched logging
        let logFlushTimer = null;
        const LOG_FLUSH_INTERVAL = 150; // Flush logs every 150ms
        const MAX_LOG_ENTRIES = 100; // Maximum log entries to keep in DOM
        
        // Image queue system for synchronized playback
        let imageQueue = []; // Queue of pending images to display after audio
        let isWaitingForAudioEnd = false; // Flag to track if we're waiting for audio to finish
        let pendingImageForCurrentAudio = null; // Image to show when current audio chunk ends
        
        // Mood list cache
        let moodListCache = null; // Cache for mood list from API
        let moodListFetchPromise = null; // Promise to prevent duplicate fetches
        
        // Image batching for text chat mode
        let currentImageContainer = null; // Current image container element
        
        // Keep-alive mechanism
        let keepAliveTimer = null;
        const KEEP_ALIVE_INTERVAL = 20000; // 20 seconds
        let lastActivityTime = 0;
        
        // Auto-reopen mic after turn complete
        let turnCompleteReceived = false; // Flag khi nh·∫≠n turn_complete t·ª´ server
        let lastAudioChunkEndTime = 0; // Th·ªùi gian chunk cu·ªëi c√πng s·∫Ω ph√°t xong
        let autoReopenTimer = null; // Timer ƒë·ªÉ check v√† reopen mic
        let imageListeningUrl = null; // Image to show when mic is opened (from turn_complete)
        
        // Connection timeout
        const CONNECTION_TIMEOUT_MS = 30000; // 30 seconds
        let connectionTimer = null; // Timer ƒë·ªÉ timeout connection
        
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const micBtn = document.getElementById('micBtn');
        const statusDiv = document.getElementById('status');
        const logBox = document.getElementById('logBox');
        const transcriptDiv = document.getElementById('transcript');
        const wsUrlInput = document.getElementById('wsUrl');
        const userIdInput = document.getElementById('userId');
        const todoIdInput = document.getElementById('todoId');
        const todoSelect = document.getElementById('todoSelect');
        const modeSttRadio = document.getElementById('modeStt');
        const modeDirectRadio = document.getElementById('modeDirectAudio');
        const modeTextChatRadio = document.getElementById('modeTextChat');
        const asrTypeSelect = document.getElementById('asrType');
        
        // Text chat elements
        const voiceControls = document.getElementById('voiceControls');
        const textChatControls = document.getElementById('textChatControls');
        const chatMessages = document.getElementById('chatMessages');
        const chatInput = document.getElementById('chatInput');
        const sendBtn = document.getElementById('sendBtn');
        let currentLoadingMessage = null;
        
        // Store todos data
        let todosData = [];
        
        // Voice mode image elements
        const voiceImageDisplay = document.getElementById('voiceImageDisplay');
        const voiceImageContainer = document.getElementById('voiceImageContainer');
        const voiceImagePlaceholder = document.getElementById('voiceImagePlaceholder');
        const voiceDisplayImage = document.getElementById('voiceDisplayImage');
        const voiceMoodInfo = document.getElementById('voiceMoodInfo');
        const voiceServoInfo = document.getElementById('voiceServoInfo');

        // Auto-detect WebSocket URL from current page
        function getDefaultWebSocketUrl() {
            if (!window.location.host) return '';
            
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const host = window.location.host;
            
            if (audioMode === 'text') {
                return `${protocol}//${host}/personalized-ai-coach/api/v1/bot/ws/benchmark/string?benchmark_type=agent`;
            } else {
                return `${protocol}//${host}/personalized-ai-coach/api/v1/bot/ws/audio2audio/string?asr_type=grpc`;
            }
        }
        
        if (window.location.host) {
            wsUrlInput.value = getDefaultWebSocketUrl();
        }
        
        // Update WebSocket URL when ASR type changes
        function updateWebSocketUrl() {
            const asrType = asrTypeSelect.value;
            const currentUrl = wsUrlInput.value;
            const urlObj = new URL(currentUrl, window.location.origin);
            urlObj.searchParams.set('asr_type', asrType);
            wsUrlInput.value = urlObj.toString();
            log(`ASR type changed to: ${asrType}`, 'info');
        }
        
        asrTypeSelect.addEventListener('change', updateWebSocketUrl);

        // Advanced settings toggle
        const advancedToggle = document.getElementById('advancedToggle');
        const advancedContent = document.getElementById('advancedContent');
        
        advancedToggle.addEventListener('click', () => {
            advancedToggle.classList.toggle('expanded');
            advancedContent.classList.toggle('show');
        });

        // Update audio mode when radio buttons change
        function updateAudioMode() {
            if (modeTextChatRadio.checked) {
                audioMode = 'text';
            } else if (modeSttRadio.checked) {
                audioMode = 'stt';
            } else {
                audioMode = 'direct';
            }
            
            log(`Switched to ${audioMode.toUpperCase()} mode`, 'info');
            
            // Toggle UI visibility
            if (audioMode === 'text') {
                voiceControls.style.display = 'none';
                textChatControls.style.display = 'block';
                voiceImageDisplay.style.display = 'none';
            } else {
                voiceControls.style.display = 'block';
                textChatControls.style.display = 'none';
                voiceImageDisplay.style.display = 'block';
                
                // Update help text for voice modes
                const helpText = document.getElementById('helpText');
                if (audioMode === 'stt') {
                    helpText.textContent = 'Nh·∫•n gi·ªØ n√∫t mic ho·∫∑c ph√≠m Space ƒë·ªÉ n√≥i (Push-to-talk)';
                } else {
                    helpText.textContent = 'Nh·∫•n n√∫t mic ho·∫∑c Space ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m (T·ª± ƒë·ªông d·ª´ng khi server ph·∫£n h·ªìi)';
                }
            }
            
            // Stop current recording if active
            if (isRecording) {
                stopRecording();
            }
        }

        modeSttRadio.addEventListener('change', () => {
            updateAudioMode();
            wsUrlInput.value = getDefaultWebSocketUrl();
        });
        modeDirectRadio.addEventListener('change', () => {
            updateAudioMode();
            wsUrlInput.value = getDefaultWebSocketUrl();
        });
        modeTextChatRadio.addEventListener('change', () => {
            updateAudioMode();
            wsUrlInput.value = getDefaultWebSocketUrl();
        });

        // Fetch todos from API
        async function fetchTodoList() {
            try {
                log('ƒêang t·∫£i danh s√°ch todos...', 'info');
                const response = await fetch('https://robot-api-hackathon.hacknao.edu.vn/robot/api/v1/open-api/to-do-list', {
                    method: 'GET',
                    headers: {
                        'accept': '*/*'
                    }
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                
                const result = await response.json();
                
                if (result.status === 200 && result.data) {
                    todosData = result.data;
                    populateTodoDropdown(todosData);
                    log(`‚úÖ ƒê√£ t·∫£i ${todosData.length} todos`, 'success');
                } else {
                    throw new Error('Invalid response format');
                }
            } catch (error) {
                log(`‚ùå L·ªói khi t·∫£i todos: ${error.message}`, 'error');
                todoSelect.innerHTML = '<option value="">Error loading todos</option>';
            }
        }

        // Populate todo dropdown
        function populateTodoDropdown(todos) {
            // Clear existing options
            todoSelect.innerHTML = '';
            
            // Find default todo (status_action = true)
            let defaultTodo = todos.find(todo => todo.status_action === true);
            
            // If no default found, use first todo
            if (!defaultTodo && todos.length > 0) {
                defaultTodo = todos[0];
            }
            
            // Add options
            todos.forEach(todo => {
                const option = document.createElement('option');
                option.value = todo.id;
                option.textContent = `${todo.name} (${todo.data.length} items)`;
                
                // Mark as selected if this is the default
                if (defaultTodo && todo.id === defaultTodo.id) {
                    option.selected = true;
                }
                
                todoSelect.appendChild(option);
            });
            
            // Set initial todo ID
            if (defaultTodo) {
                todoIdInput.value = defaultTodo.id;
                log(`‚úÖ Default todo selected: "${defaultTodo.name}" (${defaultTodo.id})`, 'success');
            }
        }

        // Handle todo selection change
        todoSelect.addEventListener('change', (e) => {
            const selectedId = e.target.value;
            todoIdInput.value = selectedId;
            
            const selectedTodo = todosData.find(todo => todo.id === selectedId);
            if (selectedTodo) {
                log(`Todo changed to: "${selectedTodo.name}" (${selectedId})`, 'info');
            }
        });

        // Initialize conversation with API
        async function initConversation(userId, todoId, conversationId) {
            try {
                log('ƒêang kh·ªüi t·∫°o conversation...', 'info');
                const protocol = window.location.protocol;
                const host = window.location.host; // This will give you the host (domain + port if present)
                
                const apiUrl = `${protocol}//${host}/personalized-ai-coach/api/v1/bot/initConversation`;
                log(`üì° Sending conversation_id: ${conversationId}`, 'info');
                
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'accept': 'application/json',
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        conversation_id: conversationId,
                        user_id: userId,
                        todo_id: todoId
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                
                const result = await response.json();
                log(`‚úÖ Conversation initialized: ${JSON.stringify(result)}`, 'success');
                return result;
            } catch (error) {
                log(`‚ùå Failed to init conversation: ${error.message}`, 'error');
                throw error;
            }
        }

        // Keep-alive functions
        function startKeepAlive() {
            stopKeepAlive(); // Clear existing timer
            lastActivityTime = Date.now();
            
            keepAliveTimer = setInterval(() => {
                const idleTime = Date.now() - lastActivityTime;
                
                // Only send if truly idle (no recording, no audio playing)
                if (idleTime >= KEEP_ALIVE_INTERVAL && !isRecording && !isPlayingAudio) {
                    sendKeepAlive();
                }
            }, KEEP_ALIVE_INTERVAL);
            
            log('Keep-alive started (20s interval)', 'info');
        }

        function stopKeepAlive() {
            if (keepAliveTimer) {
                clearInterval(keepAliveTimer);
                keepAliveTimer = null;
                log('Keep-alive stopped', 'info');
            }
        }

        function sendKeepAlive() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "ping" }));
                log('üì° Sent keep-alive ping', 'info');
                lastActivityTime = Date.now();
            }
        }

        function updateActivity() {
            lastActivityTime = Date.now();
        }

        // Auto-reopen mic functions
        function scheduleAutoReopenMic() {
            // Clear timer c≈© n·∫øu c√≥
            if (autoReopenTimer) {
                clearTimeout(autoReopenTimer);
            }
            
            // T√≠nh th·ªùi gian c·∫ßn ƒë·ª£i
            if (!audioContext) {
                log('Cannot schedule auto-reopen: no audio context', 'warn');
                return;
            }
            
            const currentTime = audioContext.currentTime;
            const waitTime = Math.max(0, lastAudioChunkEndTime - currentTime);
            
            // Th√™m buffer 100ms ƒë·ªÉ ch·∫Øc ch·∫Øn audio ƒë√£ ph√°t xong
            const delayMs = (waitTime * 1000) + 100;
            
            log(`‚è±Ô∏è Scheduling auto-reopen mic in ${delayMs.toFixed(0)}ms`, 'info');
            
            autoReopenTimer = setTimeout(() => {
                reopenMicAfterTurnComplete();
            }, delayMs);
        }

        function reopenMicAfterTurnComplete() {
            log('üîç Checking auto-reopen conditions...', 'info');
            
            // Ki·ªÉm tra ƒëi·ªÅu ki·ªán
            if (!turnCompleteReceived) {
                log('‚ùå Auto-reopen cancelled: turn not complete', 'warn');
                return;
            }
            
            if (isRecording) {
                log('‚ö†Ô∏è Auto-reopen skipped: already recording', 'info');
                return;
            }
            
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                log('‚ùå Auto-reopen skipped: WebSocket not connected', 'warn');
                return;
            }
            
            // Verify audio ƒë√£ ph√°t xong
            const currentAudioTime = audioContext ? audioContext.currentTime : 0;
            const remainingAudioTime = lastAudioChunkEndTime - currentAudioTime;
            log(`‚è±Ô∏è Audio check: current=${currentAudioTime.toFixed(3)}s, end=${lastAudioChunkEndTime.toFixed(3)}s, remaining=${remainingAudioTime.toFixed(3)}s`, 'info');
            
            if (audioContext && currentAudioTime < lastAudioChunkEndTime - 0.05) {
                log(`‚è∏Ô∏è Audio still playing (${remainingAudioTime.toFixed(3)}s remaining), rescheduling...`, 'warn');
                scheduleAutoReopenMic(); // Reschedule
                return;
            }
            
            // Ch·ªâ auto-reopen trong ch·∫ø ƒë·ªô Direct Audio
            if (audioMode !== 'direct') {
                log(`‚ö†Ô∏è Auto-reopen skipped: not in direct audio mode (current: ${audioMode})`, 'info');
                turnCompleteReceived = false;
                return;
            }
            
            // B·∫≠t mic t·ª± ƒë·ªông
            log('‚úÖ All checks passed! Auto-reopening microphone for next turn...', 'success');
            turnCompleteReceived = false; // Reset flag
            startRecording(); // B·∫≠t mic
            log('üé§ Mic button should now be in recording state', 'success');
            
            // Hi·ªÉn th·ªã image_listening n·∫øu c√≥
            if (imageListeningUrl) {
                showServerImage(imageListeningUrl, 'listening', null);
                log(`üì∏ Displaying listening image: ${imageListeningUrl}`, 'success');
            }
        }

        // Fetch mood list from API
        async function fetchMoodList() {
            // Return cached data if available
            if (moodListCache) {
                return moodListCache;
            }
            
            // If already fetching, wait for that promise
            if (moodListFetchPromise) {
                return moodListFetchPromise;
            }
            
            // Start fetching
            moodListFetchPromise = (async () => {
                try {
                    const response = await fetch('https://robot-api.hacknao.edu.vn/robot/api/v1/llm/moods?token=b1812cb7-2513-408b-bb22-d9f91b099fbd');
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    const result = await response.json();
                    
                    if (result.status === 200 && result.data && result.data.moods) {
                        moodListCache = result.data.moods;
                        log(`ƒê√£ t·∫£i ${moodListCache.length} moods t·ª´ API`, 'success');
                        return moodListCache;
                    } else {
                        throw new Error('Invalid response format');
                    }
                } catch (error) {
                    log(`L·ªói khi t·∫£i mood list: ${error.message}`, 'error');
                    moodListFetchPromise = null; // Reset so it can retry later
                    return null;
                }
            })();
            
            return moodListFetchPromise;
        }

        // Get image URL from mood name
        async function getImageUrlFromMood(moodName) {
            if (!moodName) {
                return null;
            }
            
            const moodList = await fetchMoodList();
            if (!moodList) {
                log(`Kh√¥ng th·ªÉ l·∫•y mood list ƒë·ªÉ map mood: ${moodName}`, 'error');
                return null;
            }
            
            const mood = moodList.find(m => m.mood_name === moodName);
            if (mood && mood.url) {
                log(`ƒê√£ map mood "${moodName}" ‚Üí URL: ${mood.url}`, 'success');
                return mood.url.trim(); // Trim to remove any whitespace/newlines
            } else {
                log(`Kh√¥ng t√¨m th·∫•y mood "${moodName}" trong mood list`, 'error');
                return null;
            }
        }

        // Image display function - now handles both text and voice modes
        function showServerImage(imageUrl, mood, servo) {
            if (!imageUrl) {
                return;
            }
            
            if (audioMode === 'text') {
                // Get or create image container
                const container = createImageContainer();
                
                // Add image to container
                const img = document.createElement('img');
                img.src = imageUrl;
                img.alt = mood || 'Server Response Image';
                img.title = `Mood: ${mood || 'N/A'} | Servo: ${servo || 'N/A'}`;
                
                container.appendChild(img);
                
                // Auto scroll to bottom
                chatMessages.parentElement.scrollTop = chatMessages.parentElement.scrollHeight;
                
                log(`Th√™m h√¨nh ·∫£nh: ${imageUrl} (Mood: ${mood || 'N/A'}, Servo: ${servo || 'N/A'})`, 'success');
            } else {
                // Voice mode - use standalone image display
                if (!imageUrl) {
                    voiceImageContainer.style.display = 'none';
                    voiceImagePlaceholder.style.display = 'block';
                    return;
                }

                voiceDisplayImage.src = imageUrl;
                voiceDisplayImage.onload = () => {
                    voiceImageContainer.style.display = 'block';
                    voiceImagePlaceholder.style.display = 'none';
                    
                    voiceMoodInfo.textContent = mood ? `Mood: ${mood}` : '';
                    voiceServoInfo.textContent = servo ? `Servo: ${servo}` : '';
                    
                    log(`Hi·ªÉn th·ªã h√¨nh ·∫£nh: ${imageUrl} (Mood: ${mood || 'N/A'}, Servo: ${servo || 'N/A'})`, 'success');
                };
                
                voiceDisplayImage.onerror = () => {
                    log(`L·ªói t·∫£i h√¨nh ·∫£nh: ${imageUrl}`, 'error');
                    voiceImageContainer.style.display = 'none';
                    voiceImagePlaceholder.style.display = 'block';
                    voiceImagePlaceholder.textContent = '‚ùå L·ªói t·∫£i h√¨nh ·∫£nh';
                };
            }
        }

        // Queue image for display after current audio finishes
        async function queueImageForDisplay(imageUrl, mood, servo) {
            // If image is empty but mood is provided, try to get image URL from mood
            if (!imageUrl && mood) {
                log(`Image r·ªóng, ƒëang t√¨m URL t·ª´ mood: ${mood}`, 'info');
                imageUrl = await getImageUrlFromMood(mood);
                if (!imageUrl) {
                    log(`Kh√¥ng t√¨m th·∫•y URL cho mood: ${mood}`, 'error');
                    return; // Exit if we can't find the mood URL
                }
            }
            
            // If still no image URL, exit
            if (!imageUrl) {
                return;
            }
            
            const imageData = { imageUrl, mood, servo };
            
            // If no audio is currently playing or being scheduled, show image immediately
            if (!isPlayingAudio && nextPlayTime === 0) {
                showServerImage(imageUrl, mood, servo);
                log(`Hi·ªÉn th·ªã h√¨nh ·∫£nh ngay l·∫≠p t·ª©c (kh√¥ng c√≥ audio): ${imageUrl}`, 'info');
            } else {
                // Mark this image to be shown when the NEXT audio chunk finishes
                pendingImageForCurrentAudio = imageData;
                log(`ƒê√°nh d·∫•u ·∫£nh s·∫Ω hi·ªÉn th·ªã sau audio chunk ti·∫øp theo: ${imageUrl}`, 'info');
            }
        }

        // Logging function with level filtering and buffering
        function log(message, type = 'info') {
            // Map type to log level
            let level = LOG_LEVEL.INFO;
            if (type === 'debug') level = LOG_LEVEL.DEBUG;
            else if (type === 'warn') level = LOG_LEVEL.WARN;
            else if (type === 'error') level = LOG_LEVEL.ERROR;
            
            // Filter by log level
            if (level < currentLogLevel) return;
            
            const timestamp = new Date().toLocaleTimeString();
            
            let colorClass = 'log-info';
            let icon = '‚úÖ';
            if (type === 'error') {
                colorClass = 'log-error';
                icon = '‚ùå';
            } else if (type === 'success' || type === 'info') {
                colorClass = 'log-success';
                icon = '‚úÖ';
            } else if (type === 'warn') {
                colorClass = 'log-info';
                icon = '‚ö†Ô∏è';
            } else if (type === 'debug') {
                colorClass = 'log-info';
                icon = 'üîç';
            }
            
            // Add to buffer instead of immediate DOM update
            logBuffer.push({
                timestamp,
                colorClass,
                icon,
                message
            });
            
            // Schedule flush if not already scheduled
            if (!logFlushTimer) {
                logFlushTimer = setTimeout(flushLogs, LOG_FLUSH_INTERVAL);
            }
        }
        
        // Flush buffered logs to DOM in batch
        function flushLogs() {
            if (logBuffer.length === 0) {
                logFlushTimer = null;
                return;
            }
            
            // Use document fragment for efficient DOM manipulation
            const fragment = document.createDocumentFragment();
            
            logBuffer.forEach(logData => {
                const entry = document.createElement('div');
                entry.className = 'log-entry';
                entry.innerHTML = `<span class="log-time">[${logData.timestamp}]</span> <span class="${logData.colorClass}">${logData.icon} ${logData.message}</span>`;
                fragment.appendChild(entry);
            });
            
            logBox.appendChild(fragment);
            
            // Limit log entries to prevent DOM bloat
            while (logBox.children.length > MAX_LOG_ENTRIES) {
                logBox.removeChild(logBox.firstChild);
            }
            
            logBox.scrollTop = logBox.scrollHeight;
            
            // Clear buffer and timer
            logBuffer = [];
            logFlushTimer = null;
        }
        
        // Clear all logs
        function clearLogs() {
            logBox.innerHTML = '';
            logBuffer = [];
            log('Logs cleared', 'info');
        }
        
        // Text chat functions
        function addChatMessage(text, sender = 'user') {
            const messageDiv = document.createElement('div');
            messageDiv.className = `chat-message ${sender}`;
            messageDiv.textContent = text;
            chatMessages.appendChild(messageDiv);
            
            // Auto scroll to bottom
            chatMessages.parentElement.scrollTop = chatMessages.parentElement.scrollHeight;
            
            return messageDiv;
        }
        
        function showLoadingMessage() {
            currentLoadingMessage = addChatMessage('Thinking', 'loading');
        }
        
        function removeLoadingMessage() {
            if (currentLoadingMessage) {
                currentLoadingMessage.remove();
                currentLoadingMessage = null;
            }
        }
        
        function createImageContainer() {
            // Create new image message if not exists
            if (!currentImageContainer) {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'chat-message image assistant';
                
                const imageContainer = document.createElement('div');
                imageContainer.className = 'chat-image-container';
                
                messageDiv.appendChild(imageContainer);
                chatMessages.appendChild(messageDiv);
                
                currentImageContainer = imageContainer;
            }
            return currentImageContainer;
        }
        
        function closeImageContainer() {
            currentImageContainer = null;
        }
        
        function addFunctionCallMessage(functionName, args) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'chat-message function-call assistant';
            
            // Header with icon and function name
            const header = document.createElement('div');
            header.className = 'function-call-header';
            
            const icon = document.createElement('span');
            icon.className = 'function-call-icon';
            icon.textContent = 'üîß'; // Tool icon
            
            const nameLabel = document.createElement('span');
            nameLabel.textContent = 'Function Call: ';
            
            const name = document.createElement('span');
            name.className = 'function-call-name';
            name.textContent = functionName;
            
            header.appendChild(icon);
            header.appendChild(nameLabel);
            header.appendChild(name);
            
            messageDiv.appendChild(header);
            
            // Arguments section
            if (args) {
                const argsLabel = document.createElement('div');
                argsLabel.className = 'function-call-label';
                argsLabel.textContent = 'Arguments:';
                
                const argsDiv = document.createElement('div');
                argsDiv.className = 'function-call-args';
                
                // Try to format JSON nicely
                try {
                    const parsedArgs = typeof args === 'string' ? JSON.parse(args) : args;
                    argsDiv.textContent = JSON.stringify(parsedArgs, null, 2);
                } catch (e) {
                    argsDiv.textContent = args;
                }
                
                messageDiv.appendChild(argsLabel);
                messageDiv.appendChild(argsDiv);
            }
            
            chatMessages.appendChild(messageDiv);
            
            // Auto scroll to bottom
            chatMessages.parentElement.scrollTop = chatMessages.parentElement.scrollHeight;
            
            log(`Function call: ${functionName}(${args})`, 'info');
            
            return messageDiv;
        }
        
        function showLoadingMessage() {
            currentLoadingMessage = addChatMessage('Thinking', 'loading');
        }
        
        function removeLoadingMessage() {
            if (currentLoadingMessage) {
                currentLoadingMessage.remove();
                currentLoadingMessage = null;
            }
        }
        
        function sendTextMessage() {
            const text = chatInput.value.trim();
            if (!text) return;
            
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                log('WebSocket not connected', 'error');
                return;
            }
            
            // Close image container when user sends new message
            closeImageContainer();
            
            // Add user message to chat
            addChatMessage(text, 'user');
            log(`Sent text: "${text}"`, 'info');
            
            // Send to WebSocket
            ws.send(JSON.stringify({
                type: 'text',
                text: text
            }));
            
            // Clear input and show loading
            chatInput.value = '';
            showLoadingMessage();
            
            updateActivity();
        }
        
        // Text chat functions
        function addChatMessage(text, sender = 'user') {
            const messageDiv = document.createElement('div');
            messageDiv.className = `chat-message ${sender}`;
            messageDiv.textContent = text;
            chatMessages.appendChild(messageDiv);
            
            // Auto scroll to bottom
            chatMessages.parentElement.scrollTop = chatMessages.parentElement.scrollHeight;
            
            return messageDiv;
        }
        
        function showLoadingMessage() {
            currentLoadingMessage = addChatMessage('Thinking', 'loading');
        }
        
        function removeLoadingMessage() {
            if (currentLoadingMessage) {
                currentLoadingMessage.remove();
                currentLoadingMessage = null;
            }
        }
        
        function sendTextMessage() {
            const text = chatInput.value.trim();
            if (!text) return;
            
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                log('WebSocket not connected', 'error');
                return;
            }
            
            // Add user message to chat
            addChatMessage(text, 'user');
            log(`Sent text: "${text}"`, 'info');
            
            // Send to WebSocket
            ws.send(JSON.stringify({
                type: 'text',
                text: text
            }));
            
            // Clear input and show loading
            chatInput.value = '';
            showLoadingMessage();
            
            updateActivity();
        }

        // Initialize Web Speech API
        function initSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                log('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Speech API', 'error');
                return false;
            }

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.lang = 'vi-VN';
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;

            recognition.onstart = () => {
                log('B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán gi·ªçng n√≥i', 'success');
                statusDiv.className = 'status listening';
                statusDiv.textContent = 'üé§ ƒêang nghe...';
                lastRecognitionEventAt = Date.now();
            };

            recognition.onresult = (event) => {
                lastRecognitionEventAt = Date.now();
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                // Update UI
                if (finalTranscript) {
                    transcriptDiv.textContent = finalTranscript;
                    log(`VƒÉn b·∫£n nh·∫≠n di·ªán: "${finalTranscript.trim()}"`, 'success');
                    
                    // Send to WebSocket
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const message = {
                            type: 'text',
                            text: finalTranscript.trim()
                        };
                        ws.send(JSON.stringify(message));
                        log('ƒê√£ g·ª≠i text qua WebSocket', 'success');
                    }
                } else if (interimTranscript) {
                    transcriptDiv.textContent = interimTranscript + '...';
                }
            };

            recognition.onerror = (event) => {
                log(`L·ªói nh·∫≠n di·ªán: ${event.error}`, 'error');
                // Auto recover for common transient errors
                if (isRecording && ['no-speech','audio-capture','network','aborted'].includes(event.error)) {
                    setTimeout(() => {
                        try { recognition.start(); } catch(_){}
                    }, 200);
                }
            };

            recognition.onend = () => {
                if (isRecording) {
                    log('T·ª± ƒë·ªông kh·ªüi ƒë·ªông l·∫°i nh·∫≠n di·ªán...', 'info');
                    setTimeout(() => {
                        try { recognition.start(); } catch(_){}
                    }, 150);
                } else {
                    log('D·ª´ng nh·∫≠n di·ªán gi·ªçng n√≥i', 'info');
                    statusDiv.className = 'status connected';
                    statusDiv.textContent = '‚úÖ Connected';
                }
            };

            recognition.onaudioend = () => {
                // Some browsers fire audioend before end; keep it alive if recording
                if (isRecording) {
                    setTimeout(() => {
                        try { recognition.start(); } catch(_){}
                    }, 200);
                }
            };

            recognition.onspeechend = () => {
                lastRecognitionEventAt = Date.now();
            };

            return true;
        }

        // Initialize Audio Context for playback
        function initAudioContext() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000
            });
            // Create a master gain so we can immediately mute without popping
            masterGain = audioContext.createGain();
            masterGain.gain.value = 1.0;
            masterGain.connect(audioContext.destination);
            log('Audio Context initialized (16kHz + master gain)', 'success');
        }

        // Stop all audio playback
        function stopAudioPlayback() {
            // Stop any tracked sources (including future scheduled ones)
            if (activeSources.size > 0) {
                activeSources.forEach((src) => {
                    try { src.stop(0); } catch (_) {}
                    try { src.disconnect(); } catch (_) {}
                });
                activeSources.clear();
            }
            // Legacy single ref
            if (currentSourceNode) {
                try { currentSourceNode.stop(); } catch (_) {}
                try { currentSourceNode.disconnect(); } catch (_) {}
                currentSourceNode = null;
            }
            isPlayingAudio = false;
            audioQueue = [];
            nextPlayTime = 0;
            
            // Clear image queue since we're stopping all audio
            imageQueue = [];
            isWaitingForAudioEnd = false;
            pendingImageForCurrentAudio = null;
        }

        // Play PCM audio data with seamless queueing
        function playPCMAudio(pcmData) {
            if (!audioContext) {
                log('Audio Context ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o', 'error');
                return;
            }

            updateActivity(); // Mark activity when playing audio

            // If muted (user is speaking), drop incoming audio and reset schedule
            if (isMuted) {
                nextPlayTime = 0;
                return;
            }

            // Convert PCM bytes to Float32Array
            // Ensure we respect byteOffset and byteLength boundaries
            const byteOffset = pcmData.byteOffset || 0;
            const byteLength = pcmData.byteLength || pcmData.length || 0;
            const samples = Math.floor(byteLength / 2);
            const int16Array = new Int16Array(pcmData.buffer, byteOffset, samples);
            const float32Array = new Float32Array(int16Array.length);
            
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0; // Convert to -1.0 to 1.0
            }

            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, float32Array.length, 16000);
            audioBuffer.getChannelData(0).set(float32Array);

            // Create source
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            // Route through masterGain for instant mute
            source.connect(masterGain ?? audioContext.destination);
            
            // Calculate when to start this chunk
            const currentTime = audioContext.currentTime;
            
            // If this is the first chunk or we're behind schedule, start immediately
            if (nextPlayTime === 0 || nextPlayTime < currentTime) {
                nextPlayTime = currentTime;
            }
            
            // Schedule this chunk to play at the right time
            source.start(nextPlayTime);
            
            // Update next play time to be right after this chunk ends
            const duration = audioBuffer.duration;
            nextPlayTime += duration;
            
            // Track khi chunk n√†y s·∫Ω k·∫øt th√∫c (cho auto-reopen mic)
            lastAudioChunkEndTime = nextPlayTime;
            
            // Capture the pending image for THIS audio chunk
            const imageToShowAfterThisChunk = pendingImageForCurrentAudio;
            pendingImageForCurrentAudio = null; // Clear it so next audio gets next image
            
            // Track when audio ends
            source.onended = () => {
                activeSources.delete(source);
                
                // If this chunk had an associated image, show it now
                if (imageToShowAfterThisChunk) {
                    showServerImage(
                        imageToShowAfterThisChunk.imageUrl, 
                        imageToShowAfterThisChunk.mood, 
                        imageToShowAfterThisChunk.servo
                    );
                    log('Audio chunk finished - displaying associated image', 'success');
                }
                
                // Check if we're done with all queued audio
                if (audioContext.currentTime >= nextPlayTime - 0.1) {
                    isPlayingAudio = false;
                    currentSourceNode = null;
                    nextPlayTime = 0;
                }
            };
            
            currentSourceNode = source;
            activeSources.add(source);
            isPlayingAudio = true;
            log(`Ph√°t audio (${pcmData.length} bytes, duration: ${duration.toFixed(3)}s)`, 'debug'); // Changed to debug level
        }

        // Connect WebSocket
        async function connect() {
            // Prevent double-click during connection
            if (connectBtn.disabled) {
                log('‚ö†Ô∏è Connection already in progress...', 'warn');
                return;
            }
            
            // Validate user inputs
            const userId = userIdInput.value.trim();
            const todoId = todoIdInput.value.trim();
            const wsUrl = wsUrlInput.value.trim();
            
            if (!userId || !todoId) {
                log('‚ùå User ID v√† Todo ID kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!', 'error');
                alert('Vui l√≤ng nh·∫≠p User ID v√† Todo ID tr∆∞·ªõc khi k·∫øt n·ªëi!');
                return;
            }
            
            // Extract conversation_id from WebSocket URL (last segment after /, before query params)
            // Remove query parameters first (everything after ?)
            const urlWithoutParams = wsUrl.split('?')[0];
            const conversationId = urlWithoutParams.split('/').pop();
            if (!conversationId) {
                log('‚ùå Kh√¥ng th·ªÉ l·∫•y conversation_id t·ª´ WebSocket URL!', 'error');
                alert('WebSocket URL kh√¥ng h·ª£p l·ªá. Kh√¥ng t√¨m th·∫•y conversation_id!');
                return;
            }
            log(`üîç Extracted conversation_id from URL: ${conversationId}`, 'info');
            
            // Set connecting state
            connectBtn.disabled = true;
            connectBtn.textContent = '‚è≥ Connecting...';
            statusDiv.className = 'status connecting';
            statusDiv.textContent = '‚è≥ ƒêang k·∫øt n·ªëi...';
            log('üîÑ Starting connection process...', 'info');
            
            // Initialize conversation first
            try {
                log('üì° Initializing conversation...', 'info');
                await initConversation(userId, todoId, conversationId);
            } catch (error) {
                log('‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o conversation. H·ªßy k·∫øt n·ªëi.', 'error');
                alert('Kh√¥ng th·ªÉ kh·ªüi t·∫°o conversation. Vui l√≤ng ki·ªÉm tra l·∫°i th√¥ng tin!');
                
                // Reset button state on error
                connectBtn.disabled = false;
                connectBtn.textContent = 'üîå Connect & Auto-Start';
                statusDiv.className = 'status disconnected';
                statusDiv.textContent = '‚ùå Disconnected';
                return;
            }
            
            const url = wsUrlInput.value;
            log(`ƒêang k·∫øt n·ªëi t·ªõi ${url}...`, 'info');

            // Set connection timeout
            connectionTimer = setTimeout(() => {
                if (ws && ws.readyState !== WebSocket.OPEN) {
                    log(`‚ùå Connection timeout after ${CONNECTION_TIMEOUT_MS/1000}s`, 'error');
                    
                    // Close the WebSocket if still connecting
                    if (ws) {
                        ws.close();
                        ws = null;
                    }
                    
                    // Reset button state
                    connectBtn.disabled = false;
                    connectBtn.textContent = 'üîå Connect & Auto-Start';
                    statusDiv.className = 'status disconnected';
                    statusDiv.textContent = '‚ùå Connection Timeout';
                    
                    alert(`Kh√¥ng th·ªÉ k·∫øt n·ªëi sau ${CONNECTION_TIMEOUT_MS/1000}s. Vui l√≤ng ki·ªÉm tra URL v√† th·ª≠ l·∫°i!`);
                }
            }, CONNECTION_TIMEOUT_MS);

            ws = new WebSocket(url);
            // Receive raw binary as ArrayBuffer to reduce overhead
            ws.binaryType = 'arraybuffer';

            ws.onopen = async () => {
                // Clear connection timeout
                if (connectionTimer) {
                    clearTimeout(connectionTimer);
                    connectionTimer = null;
                }
                
                log('WebSocket connected!', 'success');
                statusDiv.className = 'status connected';
                statusDiv.textContent = '‚úÖ Connected';
                
                connectBtn.style.display = 'none';
                disconnectBtn.style.display = 'inline-block';
                
                if (audioMode === 'text') {
                    chatInput.disabled = false;
                    sendBtn.disabled = false;
                } else {
                    micBtn.disabled = false;
                }

                // Initialize image display FIRST (before any async operations)
                // This prevents the reset from happening after server sends first image
                if (audioMode !== 'text') {
                    voiceImageContainer.style.display = 'none';
                    voiceImagePlaceholder.style.display = 'block';
                    voiceImagePlaceholder.textContent = 'üñºÔ∏è Ch·ªù h√¨nh ·∫£nh t·ª´ server...';
                }

                // Initialize audio context (only for voice modes)
                if (audioMode !== 'text') {
                    if (!audioContext) {
                        initAudioContext();
                    }
                    // Ensure audio is allowed to play after user gesture
                    try { await audioContext.resume(); } catch (_) {}
                }

                // Initialize speech recognition (only for STT mode)
                if (audioMode === 'stt' && !recognition) {
                    if (!initSpeechRecognition()) {
                        log('Kh√¥ng th·ªÉ kh·ªüi t·∫°o Speech Recognition', 'error');
                        return;
                    }
                }
                
                // Initialize audio stream for Direct Audio mode (ƒë·ªÉ s·∫µn s√†ng cho auto-reopen)
                if (audioMode === 'direct' && !audioStream) {
                    log('ƒêang kh·ªüi t·∫°o audio stream cho Direct Audio mode...', 'info');
                    const streamInitialized = await initDirectAudio();
                    if (streamInitialized) {
                        log('‚úÖ Audio stream s·∫µn s√†ng cho auto-reopen mic', 'success');
                    } else {
                        log('‚ö†Ô∏è Kh√¥ng th·ªÉ kh·ªüi t·∫°o audio stream - auto-reopen mic c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông', 'warn');
                    }
                }
                
                // Prefetch mood list to have it ready (only for voice modes)
                if (audioMode !== 'text') {
                    log('ƒêang prefetch mood list...', 'info');
                    fetchMoodList().then(moods => {
                        if (moods) {
                            log(`Prefetch mood list th√†nh c√¥ng: ${moods.length} moods`, 'success');
                        }
                    }).catch(err => {
                        log(`L·ªói khi prefetch mood list: ${err.message}`, 'error');
                    });
                }
                
                // Start keep-alive mechanism
                startKeepAlive();
            };

            ws.onmessage = async (event) => {
                updateActivity(); // Mark activity on any message received
                
                if (event.data instanceof ArrayBuffer) {
                    // Fast path: ArrayBuffer binary audio
                    const uint8Array = new Uint8Array(event.data);
                    if (uint8Array.byteLength > 0) {
                        log(`Nh·∫≠n ƒë∆∞·ª£c audio data: ${uint8Array.length} bytes`, 'debug'); // Changed to debug level
                        if (!isMuted && performance.now() >= dropUntilTs) {
                            playPCMAudio(uint8Array);
                        } else {
                            nextPlayTime = 0; // skip while muted
                        }
                    }
                } else if (event.data instanceof Blob) {
                    // Fallback path: Blob binary audio
                    const arrayBuffer = await event.data.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    if (uint8Array.byteLength > 0) {
                        log(`Nh·∫≠n ƒë∆∞·ª£c audio data (Blob): ${uint8Array.length} bytes`, 'debug'); // Changed to debug level
                        if (!isMuted && performance.now() >= dropUntilTs) {
                            playPCMAudio(uint8Array);
                        } else {
                            nextPlayTime = 0;
                        }
                    }
                } else {
                    // Handle text chat mode messages first
                    if (audioMode === 'text') {
                        try {
                            const message = JSON.parse(event.data);
                            console.log('üì® [TEXT MODE] Received message:', message);
                            log(`Received message: ${JSON.stringify(message)}`, 'debug');
                            
                            // Handle end_session signal to disconnect WebSocket
                            if (message.type === 'end_session') {
                                console.log('üîå [END SESSION]', message);
                                log('üîå Received end_session signal - closing WebSocket connection', 'info');
                                removeLoadingMessage();
                                addChatMessage('Session ended by server', 'system');
                                disconnect();
                                return;
                            }
                            
                            // Handle function_call
                            if (message.type === 'function_call' && message.data) {
                                console.log('üîß [FUNCTION CALL]', {
                                    type: message.type,
                                    function_name: message.data.function_name,
                                    arguments: message.data.arguments,
                                    full_message: message
                                });
                                removeLoadingMessage();
                                const functionName = message.data.function_name;
                                const args = message.data.arguments;
                                addFunctionCallMessage(functionName, args);
                            }
                            
                            // Handle other_modalities for image display
                            if (message.type === 'other_modalities' && message.data) {
                                console.log('üñºÔ∏è [IMAGE/MODALITIES]', {
                                    type: message.type,
                                    image: message.data.image,
                                    mood: message.data.mood,
                                    servo: message.data.servo,
                                    full_message: message
                                });
                                const imageUrl = message.data.image;
                                const mood = message.data.mood;
                                const servo = message.data.servo;
                                
                                if (imageUrl || mood) {
                                    // Show image immediately in text mode (no audio to wait for)
                                    if (imageUrl) {
                                        showServerImage(imageUrl, mood, servo);
                                    } else if (mood) {
                                        // Map mood to image URL
                                        getImageUrlFromMood(mood).then(url => {
                                            if (url) {
                                                showServerImage(url, mood, servo);
                                            }
                                        });
                                    }
                                }
                            }
                            
                            if (message.type === 'message' && message.data) {
                                console.log('üí¨ [MESSAGE]', {
                                    type: message.type,
                                    data_type: message.data.type,
                                    content: message.data.content,
                                    is_finished: message.data.is_finished,
                                    full_message: message
                                });
                                const data = message.data;
                                
                                if (data.type === 'output') {
                                    // Close image container before showing text
                                    closeImageContainer();
                                    
                                    removeLoadingMessage();
                                    
                                    if (data.content) {
                                        addChatMessage(data.content, 'assistant');
                                        log(`Assistant: "${data.content}"`, 'success');
                                    }
                                    
                                    if (data.is_finished) {
                                        log('Response finished', 'info');
                                    }
                                }
                            } else if (message.type === 'pong') {
                                console.log('üèì [PONG]', message);
                                log('Received pong', 'debug');
                            }
                        } catch (error) {
                            log(`Error parsing text message: ${error.message}`, 'error');
                        }
                        return;
                    }
                    
                    // Handle voice mode messages
                    // Received text message
                    console.log('üì® Server text data:', event.data);
                    try {
                        const data = JSON.parse(event.data);
                        console.log('üì® Server JSON data:', data);
                        
                        // Handle pong response
                        if (data.type === 'pong') {
                            log('üì° Received pong from server', 'info');
                            return;
                        }
                        
                        // Handle end_session signal to disconnect WebSocket
                        if (data.type === 'end_session') {
                            log('üîå Received end_session signal - closing WebSocket connection', 'info');
                            disconnect();
                            return;
                        }
                        
                        // Handle end_user_audio signal to stop recording in Direct Audio mode
                        if (data.type === 'end_user_audio' && audioMode === 'direct' && isRecording) {
                            log('üõë Received end_user_audio signal - stopping recording WITHOUT grace period', 'info');
                            stopRecording(true); // Skip grace period to accept immediate audio response
                        }
                        
                        // Handle turn_complete signal to schedule auto-reopen mic
                        if (data.type === 'turn_complete') {
                            log('‚úÖ Turn complete - server finished sending audio', 'success');
                            turnCompleteReceived = true;
                            
                            // L∆∞u image_listening n·∫øu c√≥
                            if (data.data && data.data.image_listening) {
                                imageListeningUrl = data.data.image_listening;
                                log(`üíæ Saved listening image URL: ${imageListeningUrl}`, 'info');
                            } else {
                                imageListeningUrl = null; // Reset if no image
                            }
                            
                            scheduleAutoReopenMic();
                        }
                        
                        // Handle other_modalities for image display
                        if (data.type === 'other_modalities' && data.data) {
                            const imageUrl = data.data.image;
                            const mood = data.data.mood;
                            const servo = data.data.servo;
                            
                            if (imageUrl || mood) {
                                // Queue the image to be displayed after current audio finishes
                                // Will fallback to map mood -> URL if imageUrl is empty
                                queueImageForDisplay(imageUrl, mood, servo);
                            }
                        }
                        
                        log(`Nh·∫≠n message: ${JSON.stringify(data)}`, 'info');
                    } catch (e) {
                        console.log('üì® Server raw text:', event.data);
                        log(`Nh·∫≠n text: ${event.data}`, 'info');
                    }
                }
            };

            ws.onerror = (error) => {
                // Clear connection timeout
                if (connectionTimer) {
                    clearTimeout(connectionTimer);
                    connectionTimer = null;
                }
                
                log('‚ùå WebSocket error!', 'error');
                console.error('WebSocket error:', error);
                
                // Reset button state on error
                connectBtn.disabled = false;
                connectBtn.textContent = 'üîå Connect & Auto-Start';
                connectBtn.style.display = 'inline-block';
                disconnectBtn.style.display = 'none';
            };

            ws.onclose = () => {
                // Clear connection timeout
                if (connectionTimer) {
                    clearTimeout(connectionTimer);
                    connectionTimer = null;
                }
                
                log('WebSocket disconnected', 'error');
                statusDiv.className = 'status disconnected';
                statusDiv.textContent = '‚ùå Disconnected';
                
                // Reset button state
                connectBtn.disabled = false;
                connectBtn.textContent = 'üîå Connect & Auto-Start';
                connectBtn.style.display = 'inline-block';
                disconnectBtn.style.display = 'none';
                micBtn.disabled = true;
                chatInput.disabled = true;
                sendBtn.disabled = true;

                stopRecording();
                stopKeepAlive(); // Stop keep-alive timer
                
                // Clear auto-reopen timer v√† reset state
                if (autoReopenTimer) {
                    clearTimeout(autoReopenTimer);
                    autoReopenTimer = null;
                }
                turnCompleteReceived = false;
                lastAudioChunkEndTime = 0;
                
                // Reset image display and clear queue
                voiceImageContainer.style.display = 'none';
                voiceImagePlaceholder.style.display = 'block';
                voiceImagePlaceholder.textContent = 'üñºÔ∏è Ch·ªù h√¨nh ·∫£nh t·ª´ server...';
                imageQueue = [];
                isWaitingForAudioEnd = false;
                pendingImageForCurrentAudio = null;
                
                ws = null;
            };
        }

        // Disconnect WebSocket
        function disconnect() {
            if (ws) {
                stopRecording();
                stopKeepAlive(); // Stop keep-alive timer
                
                // Clear connection timeout
                if (connectionTimer) {
                    clearTimeout(connectionTimer);
                    connectionTimer = null;
                }
                
                // Clear auto-reopen timer v√† reset state
                if (autoReopenTimer) {
                    clearTimeout(autoReopenTimer);
                    autoReopenTimer = null;
                }
                turnCompleteReceived = false;
                lastAudioChunkEndTime = 0;
                
                ws.close();
                log('ƒê√£ ng·∫Øt k·∫øt n·ªëi', 'info');
            }
        }

        // Initialize direct audio recording
        async function initDirectAudio() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                log('Direct audio stream initialized', 'success');
                return true;
            } catch (error) {
                log(`Failed to initialize direct audio: ${error.message}`, 'error');
                return false;
            }
        }

        // Start direct audio recording with PCM format matching server using AudioWorklet
        async function startDirectAudioRecording() {
            if (!audioStream && !(await initDirectAudio())) {
                return;
            }

            try {
                // Create AudioContext for recording (separate from playback context)
                recordingAudioContext = new AudioContext({ sampleRate: 16000 });
                
                // Load AudioWorklet processor module
                await recordingAudioContext.audioWorklet.addModule('/static/pcm-recorder-worklet.js');
                
                // Create source from microphone stream
                const source = recordingAudioContext.createMediaStreamSource(audioStream);
                
                // Create AudioWorklet node (runs on audio thread, not main thread!)
                audioWorkletNode = new AudioWorkletNode(recordingAudioContext, 'pcm-recorder-processor');
                
                // Listen for PCM data from worklet
                audioWorkletNode.port.onmessage = (event) => {
                    if (event.data.type === 'audio' && isRecording && ws && ws.readyState === WebSocket.OPEN) {
                        // Send raw PCM data to server
                        ws.send(event.data.data);
                        // No logging here - runs frequently!
                    }
                };
                
                // Connect audio graph: mic -> worklet -> destination
                source.connect(audioWorkletNode);
                audioWorkletNode.connect(recordingAudioContext.destination);
                
                // Tell worklet to start recording
                audioWorkletNode.port.postMessage({ command: 'start' });
                
                log('‚úÖ Started AudioWorklet PCM recording (16kHz, mono, int16) - runs on audio thread!', 'success');
            } catch (error) {
                log(`‚ùå Failed to start AudioWorklet recording: ${error.message}`, 'error');
                // Fallback to old method if AudioWorklet not supported
                log('‚ö†Ô∏è Falling back to ScriptProcessorNode (deprecated)', 'warn');
                await startDirectAudioRecordingFallback();
            }
        }
        
        // Fallback to ScriptProcessorNode for older browsers
        async function startDirectAudioRecordingFallback() {
            if (!audioStream) return;
            
            try {
                const audioCtx = new AudioContext({ sampleRate: 16000 });
                const source = audioCtx.createMediaStreamSource(audioStream);
                const processor = audioCtx.createScriptProcessor(1024, 1, 1);
                
                processor.onaudioprocess = (event) => {
                    if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const int16Array = new Int16Array(inputData.length);
                    
                    for (let i = 0; i < inputData.length; i++) {
                        const sample = Math.max(-1, Math.min(1, inputData[i]));
                        int16Array[i] = sample * 32767;
                    }
                    
                    ws.send(int16Array.buffer);
                };
                
                source.connect(processor);
                processor.connect(audioCtx.destination);
                
                window.audioProcessor = { audioCtx, source, processor };
                
                log('Started fallback ScriptProcessorNode recording', 'warn');
            } catch (error) {
                log(`Fallback recording failed: ${error.message}`, 'error');
            }
        }

        // Stop direct audio recording
        function stopDirectAudioRecording() {
            // Stop AudioWorklet if active
            if (audioWorkletNode) {
                try {
                    // Tell worklet to stop
                    audioWorkletNode.port.postMessage({ command: 'stop' });
                    audioWorkletNode.disconnect();
                    audioWorkletNode = null;
                } catch (e) {
                    console.warn('Error stopping AudioWorklet:', e);
                }
            }
            
            // Close recording context
            if (recordingAudioContext) {
                try {
                    recordingAudioContext.close();
                    recordingAudioContext = null;
                } catch (e) {
                    console.warn('Error closing recording context:', e);
                }
            }
            
            // Cleanup fallback ScriptProcessorNode if used
            if (window.audioProcessor) {
                try {
                    window.audioProcessor.source.disconnect();
                    window.audioProcessor.processor.disconnect();
                    window.audioProcessor.audioCtx.close();
                    delete window.audioProcessor;
                } catch (e) {
                    console.warn('Error cleaning up audio processor:', e);
                }
            }
            
            // Fallback cleanup for old MediaRecorder approach
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            
            log('Stopped direct audio recording', 'info');
        }

        // Start recording (unified for both modes)
        async function startRecording() {
            if (isRecording) {
                log('‚ö†Ô∏è startRecording called but already recording', 'warn');
                return;
            }
            
            log(`üéôÔ∏è startRecording called (mode: ${audioMode})`, 'info');
            
            updateActivity(); // Mark activity when user starts recording
            
            // Clear auto-reopen timer n·∫øu user b·∫≠t th·ªß c√¥ng
            if (autoReopenTimer) {
                clearTimeout(autoReopenTimer);
                autoReopenTimer = null;
                log('Cleared auto-reopen timer (manual start)', 'info');
            }
            turnCompleteReceived = false;
            
            // Send start_user_audio signal only for Direct Audio mode
            if (audioMode === 'direct' && ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({"type": "start_user_audio"}));
                log('Sent start_user_audio signal', 'info');
            }
            
            // Stop any playing audio when user starts talking
            if (isPlayingAudio) {
                stopAudioPlayback();
            }
            // Clear any pending images since we're interrupting the conversation
            imageQueue = [];
            isWaitingForAudioEnd = false;
            pendingImageForCurrentAudio = null;
            
            // Mute incoming audio from server while user is speaking
            isMuted = true;
            nextPlayTime = 0;
            dropUntilTs = Number.MAX_SAFE_INTEGER; // block any in-flight frames until we unmute
            // Instantly mute output volume to avoid any scheduled residue
            try {
                if (masterGain) {
                    masterGain.gain.cancelScheduledValues(audioContext.currentTime);
                    masterGain.gain.setTargetAtTime(0.0, audioContext.currentTime, 0.005);
                }
            } catch (_) {}

            // Notify backend to stop current TTS/audio stream if supported
            try {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'control', action: 'interrupt' }));
                }
            } catch (_) {}
            
            isRecording = true;
            micBtn.classList.add('recording');
            log(`‚úÖ Recording state set: isRecording=${isRecording}, classList contains 'recording'=${micBtn.classList.contains('recording')}`, 'success');

            if (audioMode === 'stt') {
                // STT Mode - use Web Speech API
                if (!recognition) {
                    log('Speech recognition not initialized', 'error');
                    return;
                }
                
                lastRecognitionEventAt = Date.now();
                // Start watchdog to ensure recognition stays alive
                if (recognitionWatchdog) clearInterval(recognitionWatchdog);
                recognitionWatchdog = setInterval(() => {
                    if (isRecording && Date.now() - lastRecognitionEventAt > RECOG_WATCHDOG_MS) {
                        log('Watchdog: kh·ªüi ƒë·ªông l·∫°i nh·∫≠n di·ªán do kh√¥ng c√≥ s·ª± ki·ªán m·ªõi', 'info');
                        try { recognition.stop(); } catch(_){ }
                        setTimeout(() => { try { recognition.start(); } catch(_){ } }, 200);
                        lastRecognitionEventAt = Date.now();
                    }
                }, 2000);
                
                try {
                    recognition.start();
                    log('B·∫Øt ƒë·∫ßu ghi √¢m v√† nh·∫≠n di·ªán STT...', 'success');
                } catch (e) {
                    log('Recognition ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông', 'info');
                }
            } else {
                // Direct Audio Mode
                log('üì° Starting Direct Audio recording...', 'info');
                await startDirectAudioRecording();
                statusDiv.className = 'status listening';
                statusDiv.textContent = 'üéµ ƒêang ghi √¢m tr·ª±c ti·∫øp...';
                log('‚úÖ Direct Audio recording started, status updated', 'success');
            }
        }

        // Stop recording (unified for both modes)
        function stopRecording(skipGracePeriod = false) {
            if (!isRecording) return;
            
            // Note: Kh√¥ng c·∫ßn clear auto-reopen timer ·ªü ƒë√¢y v√¨ auto-reopen
            // ch·ªâ trigger khi NOT recording. Nh∆∞ng reset flag ƒë·ªÉ safe.
            turnCompleteReceived = false;
            
            isRecording = false;
            micBtn.classList.remove('recording');
            
            if (audioMode === 'stt') {
                // STT Mode cleanup
                if (recognitionWatchdog) {
                    clearInterval(recognitionWatchdog);
                    recognitionWatchdog = null;
                }
                try {
                    if (recognition) recognition.stop();
                    log('D·ª´ng ghi √¢m STT', 'info');
                } catch (e) {
                    // Ignore
                }
            } else {
                // Direct Audio Mode cleanup
                stopDirectAudioRecording();
            }

            // Common cleanup
            // Unmute to resume hearing server audio
            isMuted = false;
            // Set a short grace period to drop any stale frames still in flight
            // UNLESS we're stopping because server sent end_user_audio (then we WANT the immediate response)
            if (skipGracePeriod) {
                dropUntilTs = 0; // Accept audio immediately
                log('‚ö° Stopped recording WITHOUT grace period - ready for immediate server response', 'info');
            } else {
                dropUntilTs = performance.now() + 250; // 250ms should be enough to flush old packets
                log('‚è±Ô∏è Stopped recording WITH 250ms grace period', 'info');
            }
            try {
                if (masterGain) {
                    masterGain.gain.cancelScheduledValues(audioContext.currentTime);
                    masterGain.gain.setTargetAtTime(1.0, audioContext.currentTime, 0.01);
                }
            } catch (_) {}

            // Notify backend we can resume sending fresh audio
            try {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'control', action: 'resume' }));
                }
            } catch (_) {}

            statusDiv.className = 'status connected';
            statusDiv.textContent = '‚úÖ Connected';
        }

        // Event listeners
        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);
        
        // Text chat event listeners
        sendBtn.addEventListener('click', sendTextMessage);
        chatInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                e.preventDefault();
                sendTextMessage();
            }
        });

        // Mouse events for mic button
        micBtn.addEventListener('mousedown', (e) => {
            if (audioMode === 'direct') {
                // Direct Audio mode: click to toggle
                if (!isRecording) {
                    startRecording();
                }
                // Don't stop on mouseup in direct mode - wait for server signal
            } else {
                // STT mode: push-to-talk
                startRecording();
            }
        });
        
        micBtn.addEventListener('mouseup', (e) => {
            if (audioMode === 'stt') {
                // Only stop on mouseup for STT mode
                stopRecording();
            }
            // Direct Audio mode ignores mouseup - waits for server signal
        });

        // Touch events for mobile
        micBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            if (audioMode === 'direct') {
                // Direct Audio mode: tap to toggle
                if (!isRecording) {
                    startRecording();
                }
            } else {
                // STT mode: touch-to-talk
                startRecording();
            }
        });
        
        micBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            if (audioMode === 'stt') {
                // Only stop on touchend for STT mode
                stopRecording();
            }
            // Direct Audio mode ignores touchend - waits for server signal
        });

        // Keyboard events (Space key) - only for voice modes
        document.addEventListener('keydown', (e) => {
            if (e.code === 'Space' && !micBtn.disabled && audioMode !== 'text') {
                e.preventDefault();
                if (audioMode === 'direct') {
                    // Direct Audio mode: press Space to toggle
                    if (!isRecording) {
                        startRecording();
                    }
                } else {
                    // STT mode: hold Space to talk
                    if (!isRecording) {
                        startRecording();
                    }
                }
            }
        });

        document.addEventListener('keyup', (e) => {
            if (e.code === 'Space' && audioMode === 'stt' && isRecording) {
                // Only stop on Space release for STT mode
                e.preventDefault();
                stopRecording();
            }
            // Direct Audio mode ignores Space release - waits for server signal
        });

        // Ensure cleanup on page reload/close
        window.addEventListener('beforeunload', () => {
            try { if (recognition) recognition.abort?.(); } catch (_) {}
            try { if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop(); } catch (_) {}
            try { if (audioWorkletNode) audioWorkletNode.disconnect(); } catch (_) {}
            try { if (recordingAudioContext) recordingAudioContext.close(); } catch (_) {}
            try { if (window.audioProcessor) { 
                window.audioProcessor.source.disconnect();
                window.audioProcessor.processor.disconnect();
                window.audioProcessor.audioCtx.close();
            }} catch (_) {}
            try { if (audioStream) audioStream.getTracks().forEach(track => track.stop()); } catch (_) {}
            try { if (ws && ws.readyState === WebSocket.OPEN) ws.close(); } catch (_) {}
            try { if (audioContext) audioContext.close(); } catch (_) {}
        });

        // Initial log
        log('Trang web ƒë√£ s·∫µn s√†ng. Nh·∫•n Connect ƒë·ªÉ b·∫Øt ƒë·∫ßu.', 'success');
        
        // Fetch todo list on page load
        fetchTodoList().catch(err => {
            log(`L·ªói khi t·∫£i todo list: ${err.message}`, 'error');
        });
        
        // Prefetch mood list on page load
        log('ƒêang t·∫£i mood list...', 'info');
        fetchMoodList().then(moods => {
            if (moods) {
                log(`ƒê√£ t·∫£i ${moods.length} moods t·ª´ API`, 'success');
            }
        }).catch(err => {
            log(`L·ªói khi t·∫£i mood list: ${err.message}`, 'error');
        });
    </script>
</body>
</html>
